{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — Feature Engineering\n",
    "\n",
    "Run the full feature extraction pipeline on bearing data and visualise:\n",
    "- Distribution of all 30 features\n",
    "- Correlation heatmap\n",
    "- Normal vs anomaly feature comparison\n",
    "\n",
    "**Prerequisites:** `data/raw/bearing_*.csv` must exist (run `download_data.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.path.abspath(\"../..\"))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"backend\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from app.preprocessing.signal_processing import window_signal\n",
    "from app.preprocessing.feature_extraction import FeatureExtractor, FEATURE_NAMES\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 1. Load a bearing with anomalies (bearing_3 or bearing_4)\n",
    "# ---------------------------------------------------------------------------\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "# Pick the first file that has anomalies; fall back to any available\n",
    "candidates = sorted(DATA_DIR.glob(\"bearing_*.csv\"))\n",
    "df = None\n",
    "for p in candidates:\n",
    "    _df = pd.read_csv(p)\n",
    "    if \"phase\" in _df.columns and \"anomaly\" in _df[\"phase\"].values:\n",
    "        df = _df\n",
    "        print(f\"Using {p.name} (contains anomalies)\")\n",
    "        break\n",
    "if df is None:\n",
    "    df = pd.read_csv(candidates[0])\n",
    "    print(f\"Using {candidates[0].name} (no anomaly phase)\")\n",
    "\n",
    "print(f\"Rows: {len(df):,}  |  Phases: {df['phase'].value_counts().to_dict() if 'phase' in df.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 2. Window + extract features\n",
    "# ---------------------------------------------------------------------------\n",
    "from app.preprocessing.signal_processing import DEFAULT_WINDOW_SIZE, DEFAULT_HOP_SIZE\n",
    "\n",
    "signal = df[\"ch1\"].values.astype(np.float64)\n",
    "phases = df[\"phase\"].values if \"phase\" in df.columns else np.full(len(signal), \"all\")\n",
    "\n",
    "windows = window_signal(signal)\n",
    "print(f\"Windows: {windows.shape}\")\n",
    "\n",
    "extractor = FeatureExtractor()\n",
    "features = extractor.extract(windows)   # (n_windows, 30)\n",
    "print(f\"Features: {features.shape}\")\n",
    "\n",
    "# Map phase labels to windows\n",
    "n_windows = len(windows)\n",
    "starts = np.arange(n_windows) * DEFAULT_HOP_SIZE\n",
    "window_phases = phases[starts]\n",
    "is_anomaly = (window_phases == \"anomaly\").astype(int)\n",
    "\n",
    "feat_df = pd.DataFrame(features, columns=FEATURE_NAMES)\n",
    "feat_df[\"is_anomaly\"] = is_anomaly\n",
    "feat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 3. Feature distributions — normal vs anomaly\n",
    "# ---------------------------------------------------------------------------\n",
    "n_features = 30\n",
    "cols = 5\n",
    "rows = n_features // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, rows * 3))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, name in enumerate(FEATURE_NAMES):\n",
    "    ax = axes[i]\n",
    "    normal_vals  = feat_df.loc[feat_df[\"is_anomaly\"] == 0, name].values\n",
    "    anomaly_vals = feat_df.loc[feat_df[\"is_anomaly\"] == 1, name].values\n",
    "\n",
    "    ax.hist(normal_vals,  bins=40, alpha=0.6, label=\"normal\",  color=\"steelblue\", density=True)\n",
    "    if len(anomaly_vals) > 0:\n",
    "        ax.hist(anomaly_vals, bins=40, alpha=0.6, label=\"anomaly\", color=\"tomato\",    density=True)\n",
    "    ax.set_title(name, fontsize=9)\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "plt.suptitle(\"Feature Distributions: Normal vs Anomaly\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 4. Correlation heatmap (normal data only)\n",
    "# ---------------------------------------------------------------------------\n",
    "normal_df = feat_df[feat_df[\"is_anomaly\"] == 0][FEATURE_NAMES]\n",
    "corr = normal_df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 11))\n",
    "im = ax.imshow(corr.values, cmap=\"RdBu_r\", vmin=-1, vmax=1, aspect=\"auto\")\n",
    "fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "ax.set_xticks(range(30))\n",
    "ax.set_yticks(range(30))\n",
    "ax.set_xticklabels(FEATURE_NAMES, rotation=90, fontsize=7)\n",
    "ax.set_yticklabels(FEATURE_NAMES, fontsize=7)\n",
    "ax.set_title(\"Feature Correlation Heatmap (Normal Data)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 5. Top discriminating features (mean separation)\n",
    "# ---------------------------------------------------------------------------\n",
    "if feat_df[\"is_anomaly\"].sum() > 0:\n",
    "    normal_means  = feat_df[feat_df[\"is_anomaly\"] == 0][FEATURE_NAMES].mean()\n",
    "    anomaly_means = feat_df[feat_df[\"is_anomaly\"] == 1][FEATURE_NAMES].mean()\n",
    "    normal_stds   = feat_df[feat_df[\"is_anomaly\"] == 0][FEATURE_NAMES].std()\n",
    "\n",
    "    # Normalised separation (Cohen's d-like)\n",
    "    separation = ((anomaly_means - normal_means) / (normal_stds + 1e-8)).abs().sort_values(ascending=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    separation.head(15).plot(kind=\"barh\", ax=ax, color=\"darkorange\")\n",
    "    ax.set_xlabel(\"Normalised mean separation\")\n",
    "    ax.set_title(\"Top 15 Most Discriminating Features\")\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(separation.head(10))\n",
    "else:\n",
    "    print(\"No anomaly samples in this bearing — skipping separation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Next step:** Run `train_models.py` to train the baseline Autoencoder on these features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
